{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/vanshbansal/Desktop/Road Accidents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class PreprocessingConfig:\n",
    "    root_dir: Path\n",
    "    preprocesser_obj: Path\n",
    "    train_file_path: Path\n",
    "    test_file_path: Path\n",
    "    preprocessed_x_train: Path\n",
    "    preprocessed_x_test: Path\n",
    "    preprocessed_y_train: Path\n",
    "    preprocessed_y_test: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.common import read_yaml , create_directories\n",
    "from src.constants import CONFIG_FILE_PATH\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self , config_filepath=CONFIG_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "    \n",
    "    def get_preprocessing_config(self) -> PreprocessingConfig:\n",
    "        config = self.config.preprocessing\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "\n",
    "        preprocessing_config = PreprocessingConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            preprocesser_obj = config.preprocesser_obj,\n",
    "            train_file_path = config.train_file_path,\n",
    "            test_file_path = config.test_file_path,\n",
    "            preprocessed_x_train = config.preprocessed_x_train,\n",
    "            preprocessed_x_test = config.preprocessed_x_test,\n",
    "            preprocessed_y_train = config.preprocessed_y_train,\n",
    "            preprocessed_y_test = config.preprocessed_y_test\n",
    "        )\n",
    "\n",
    "        return preprocessing_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src import logger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self , config: PreprocessingConfig):\n",
    "        try:\n",
    "            self.config = config\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def transform_x(self , x_train , x_test):\n",
    "        df = pd.read_csv(self.config.train_file_path)\n",
    "        \n",
    "        num_cols = df.select_dtypes(include=['number']).columns.tolist()  # Columns with numeric data types\n",
    "        cat_cols = df.select_dtypes(exclude=['number']).columns.tolist()  # Non-numeric columns (categorical)\n",
    "\n",
    "        # List of columns to exclude from null-checks\n",
    "        keep_cols = [\n",
    "            \"Temperature(F)\",\n",
    "            \"Humidity(%)\",\n",
    "            \"Pressure(in)\",\n",
    "            \"Visibility(mi)\",\n",
    "            \"Wind_Direction\",\n",
    "            \"Wind_Speed(mph)\",\n",
    "            \"Weather_Condition\"\n",
    "        ]\n",
    "        \n",
    "        null_int_cols = list(set(keep_cols).intersection(set(num_cols)))\n",
    "        null_cat_cols = list(set(keep_cols).intersection(set(cat_cols)))\n",
    "\n",
    "\n",
    "        # Define transformers\n",
    "        imp_enc = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num_missing\", SimpleImputer(strategy=\"median\"), null_int_cols),  # Impute missing values for numerical columns\n",
    "                (\"cat_imputer_ohe\", Pipeline(steps=[\n",
    "                    (\"cat_imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Impute missing values for categorical columns\n",
    "                    (\"ohe_trf\", OneHotEncoder(sparse_output=False, handle_unknown='ignore'))  # Apply OneHotEncoder to all categorical columns\n",
    "                ]), cat_cols),  # Apply both imputation and one-hot encoding to all categorical columns\n",
    "            ],\n",
    "            remainder='passthrough'  # Keep other columns as they are\n",
    "        )\n",
    "\n",
    "        \n",
    "        yj_trf = PowerTransformer()\n",
    "        \n",
    "        scaler_trf = ColumnTransformer([\n",
    "            (\"scaler_trf\" , StandardScaler() , slice(0,40))\n",
    "        ])\n",
    "        \n",
    "        pca = PCA(n_components=15)\n",
    "\n",
    "        pre_pipe = Pipeline([\n",
    "            (\"preprocessor\" , imp_enc),\n",
    "            (\"yj_trf\" , yj_trf),\n",
    "            (\"scaler_trf\" , scaler_trf),\n",
    "            (\"pca\" , pca)\n",
    "        ])\n",
    "\n",
    "        x_train_trf = pre_pipe.fit_transform(x_train)\n",
    "        x_test_trf = pre_pipe.transform(x_test)\n",
    "\n",
    "        np.save(self.config.preprocessed_x_train , x_train_trf)\n",
    "        np.save(self.config.preprocessed_x_test , x_test_trf)        \n",
    "        joblib.dump(pre_pipe, self.config.preprocesser_obj) \n",
    "\n",
    "\n",
    "    def transform_y(self , y_train , y_test):\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(y_train)\n",
    "\n",
    "        y_train = le.transform(y_train)\n",
    "        y_test= le.transform(y_test)\n",
    "\n",
    "        np.save(self.config.preprocessed_y_train , y_train)\n",
    "        np.save(self.config.preprocessed_y_test , y_test)\n",
    "    \n",
    "    def start_preprocessing(self):\n",
    "        \n",
    "        train_file_path = self.config.train_file_path\n",
    "        test_file_path = self.config.test_file_path\n",
    "\n",
    "        train = pd.read_csv(train_file_path)\n",
    "        test = pd.read_csv(test_file_path)\n",
    "\n",
    "        x_train = train.drop(columns=['Severity'])\n",
    "        y_train = train['Severity']\n",
    "        x_test = test.drop(columns=['Severity'])\n",
    "        y_test = test['Severity']\n",
    "\n",
    "        \n",
    "        self.transform_x(x_train , x_test)\n",
    "        self.transform_y(y_train , y_test)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-11 11:09:33,253: INFO: common: yaml file: config.yaml loaded successfully]\n",
      "[2025-01-11 11:09:33,264: INFO: common: created directory at: artifacts/preprocessing]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanshbansal/Desktop/Road Accidents/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:188: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/vanshbansal/Desktop/Road Accidents/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:199: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    preprocessing_obj = config.get_preprocessing_config()\n",
    "    preprocessing = Preprocessing(config=preprocessing_obj)\n",
    "    preprocessing.start_preprocessing()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
